{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04cbe5e4",
   "metadata": {},
   "source": [
    "# Assignment 2 Part 1 Questions #\n",
    "1. A data warehouse for a music streaming company consists of the dimensions song, user, time (time and date of when the user listened to a song), and the two measures count (how many times a user listened to the song) and fee (fee paid by the streaming company to the artist every time a user listens to that song).\n",
    "\n",
    "1. Draw a schema diagram for the above data warehouse using a star schema.\n",
    "\n",
    "1. Starting with the base cuboid [time, user, song], what specific OLAP operations should be performed in order to list the total fee collected for a given song for a given month of a given year (e.g. October 2021)?\n",
    "\n",
    "1. Assume that the time dimension has 4 levels: day, month, quarter, year; and that the song and user dimensions both have 1 level (not including the virtual level 'all'). How many cuboids will this cube contain (including the base and apex cuboids)?\n",
    "\n",
    "1. Suppose that a car rental company has a data warehouse that holds record ID lists of vehicles in terms of brands (Audi, Ford, Mini) and store branches (Tower Hamlets, Newham, Hackney). Each record consists of a combination of vehicle brand and branch, and records for all combinations exist. We would like to index the OLAP data using bitmap indices. Write down the base table for record IDs, and the corresponding bitmap index table for vehicle brand.\n",
    "\n",
    "1. Using the same CSV file and data cube in the above lab tutorial, modify the \"tutorial_model.json\" file to include aggregate measures for the minimum and maximum amount in the data cube. Using these implemented aggregate measures, produce the values for the minimum and maximum amount in the data per year. Make sure to show your workings in the PDF report. You can read the Cubes package documentation for assistance in this task.\n",
    "\n",
    "1. Using the CSV file \"country-income.csv\" (found in the week 5 supplementary lab documents), perform the following:\n",
    "\n",
    "1. Load the CSV file using Cubes, create a JSON file for the data cube model, and create a data cube for the data. Use as dimensions the region, age, and online shopper fields. Use as measure the income. Define aggregate functions in the data cube model for the total, average, minimum, and maximum income. In your PDF report, show the relevant scripts and files created.\n",
    "\n",
    "1. Using the created data cube and data cube model, produce aggregate results for: the whole data cube; results per region; results per online shopping activity; and results for all people aged between 40 and 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e04e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1472b1e8",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "# Part 1 of 2\n",
    "## Question 1\n",
    "### A\n",
    "![Star_Schema](Star_Schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d000a0",
   "metadata": {},
   "source": [
    "### B\n",
    "Roll up user to All. Song left as normal, time roll up from day to month and slice the desired month (October 2021)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c78d6",
   "metadata": {},
   "source": [
    "### C\n",
    "$\\prod_{i=1}^{n} (L_i + 1)$\n",
    "\n",
    "$(4+1)(1+1)(1+1)$\n",
    "\n",
    "$5\\times2\\times2 = 20 cuboids$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01baa439",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "### Base\n",
    "\n",
    "| RID | Brand | Branch |\n",
    "|:----|:------|:------:|\n",
    "| 01  | Audi  | Tower Hamlets |\n",
    "| 02  | Audi  | Newham |\n",
    "| 03  | Audi  | Hackney |\n",
    "| 04  | Ford  | Tower Hamlets |\n",
    "| 05  | Ford  | Newham |\n",
    "| 06  | Ford  | Hackney |\n",
    "| 07  | Mini  | Tower Hamlets |\n",
    "| 08  | Mini  | Newham |\n",
    "| 09  | Mini  | Hackney |\n",
    "\n",
    "### Bitmap for brands\n",
    "\n",
    "| RID | Audi | Ford | Mini |\n",
    "|:---:|:----:|:----:|:----:|\n",
    "| 01  | 1 | 0 | 0 |\n",
    "| 02  | 1 | 0 | 0 |\n",
    "| 03  | 1 | 0 | 0 |\n",
    "| 04  | 0 | 1 | 0 |\n",
    "| 05  | 0 | 1 | 0 |\n",
    "| 06  | 0 | 1 | 0 |\n",
    "| 07  | 0 | 0 | 1 |\n",
    "| 08  | 0 | 0 | 1 |\n",
    "| 09  | 0 | 0 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7d5f31",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### json code\n",
    "```\n",
    "{\n",
    "    \"dimensions\": [\n",
    "        {\n",
    "         \"name\":\"item\",\n",
    "         \"levels\": [\n",
    "                {\n",
    "                    \"name\":\"category\",\n",
    "                    \"label\":\"Category\",\n",
    "                    \"attributes\": [\"category\", \"category_label\"]\n",
    "                },\n",
    "                {\n",
    "                    \"name\":\"subcategory\",\n",
    "                    \"label\":\"Sub-category\",\n",
    "                    \"attributes\": [\"subcategory\", \"subcategory_label\"]\n",
    "                },\n",
    "                {\n",
    "                    \"name\":\"line_item\",\n",
    "                    \"label\":\"Line Item\",\n",
    "                    \"attributes\": [\"line_item\"]\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\"name\":\"year\", \"role\": \"time\"}\n",
    "    ],\n",
    "    \"cubes\": [\n",
    "        {\n",
    "            \"name\": \"ibrd_balance\",\n",
    "            \"dimensions\": [\"item\", \"year\"],\n",
    "            \"measures\": [{\"name\":\"amount\", \"label\":\"Amount\"}],\n",
    "            \"aggregates\": [\n",
    "                    {\n",
    "                        \"name\": \"amount_sum\",\n",
    "                        \"function\": \"sum\",\n",
    "                        \"measure\": \"amount\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"record_count\",\n",
    "                        \"function\": \"count\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"amount_min\",\n",
    "                        \"function\": \"min\",\n",
    "                        \"measure\": \"amount\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"amount_max\",\n",
    "                        \"function\": \"max\",\n",
    "                        \"measure\": \"amount\"\n",
    "                    }\n",
    "                ],\n",
    "            \"mappings\": {\n",
    "                          \"item.line_item\": \"line_item\",\n",
    "                          \"item.subcategory\": \"subcategory\",\n",
    "                          \"item.subcategory_label\": \"subcategory_label\",\n",
    "                          \"item.category\": \"category\",\n",
    "                          \"item.category_label\": \"category_label\"\n",
    "                         },\n",
    "            \"info\": {\n",
    "                \"min_date\": \"2010-01-01\",\n",
    "                \"max_date\": \"2010-12-31\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3b84954",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from cubes.tutorial.sql import create_table_from_csv\n",
    "from cubes import Workspace\n",
    "import cubes as cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57383ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data.sqlite')\n",
    "create_table_from_csv(engine,\n",
    "                      \"IBRD_Balance_Sheet__FY2010.csv\",\n",
    "                      table_name=\"ibrd_balance\",\n",
    "                      fields=[\n",
    "                          (\"category\", \"string\"),\n",
    "                          (\"category_label\", \"string\"),\n",
    "                          (\"subcategory\", \"string\"),\n",
    "                          (\"subcategory_label\", \"string\"),\n",
    "                          (\"line_item\", \"string\"),\n",
    "                          (\"year\", \"integer\"),\n",
    "                          (\"amount\", \"integer\")],\n",
    "                      create_id=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd0d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace()\n",
    "workspace.register_default_store(\"sql\", url=\"sqlite:///data.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2262443",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.import_model(\"tutorial_model.json\")\n",
    "cube = workspace.cube(\"ibrd_balance\")\n",
    "browser = workspace.browser(cube)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "aeda1095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009 : Minimum = -1683 : Maximum = 110040\n",
      "2010 : Minimum = -3043 : Maximum = 128577\n"
     ]
    }
   ],
   "source": [
    "result = browser.aggregate(drilldown=[\"year\"])\n",
    "for record in result:\n",
    "    print(str(record[\"year\"]) + \" : Minimum = \" + str(record[\"amount_min\"]) + \" : Maximum = \" +  str(record[\"amount_max\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c93898",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### A\n",
    "#### JSON Code\n",
    "`{\n",
    "    \"dimensions\": [\n",
    "        {\"name\":\"region\"},\n",
    "\t\t{\"name\":\"age\"},\n",
    "\t\t{\"name\":\"online_shop\"}\t\t\n",
    "    ],\n",
    "    \"cubes\": [\n",
    "        {\n",
    "            \"name\": \"country-income\",\n",
    "            \"dimensions\": [\"region\", \"age\", \"online_shop\"],\n",
    "            \"measures\": [{\"name\":\"income\", \"label\":\"income\"}],\n",
    "            \"aggregates\": [\n",
    "                    {\n",
    "                        \"name\": \"total\",\n",
    "                        \"function\": \"sum\",\n",
    "                        \"measure\": \"income\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"average\",\n",
    "                        \"function\": \"avg\",\n",
    "                        \"measure\": \"income\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"min\",\n",
    "                        \"function\": \"min\",\n",
    "                        \"measure\": \"income\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"name\": \"max\",\n",
    "                        \"function\": \"max\",\n",
    "                        \"measure\": \"income\"\n",
    "                    }\n",
    "                ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0788500",
   "metadata": {},
   "source": [
    "### B\n",
    "#### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1e482547",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///data2.sqlite')\n",
    "create_table_from_csv(engine,\n",
    "                      \"country-income.csv\",\n",
    "                      table_name=\"country-income\",\n",
    "                      fields=[\n",
    "                          (\"region\", \"string\"),\n",
    "                          (\"age\", \"integer\"),\n",
    "                          (\"income\", \"integer\"),\n",
    "                          (\"online_shop\", \"string\")],\n",
    "                      create_id=True\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d17a4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = Workspace()\n",
    "workspace.register_default_store(\"sql\", url=\"sqlite:///data2.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da51b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.import_model(\"country-income.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "29ccb56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = workspace.cube(\"country-income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8251ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = workspace.browser(cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30618a46",
   "metadata": {},
   "source": [
    "#### Whole Data Cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "06eec617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 768200, 'average': 76820.0, 'min': 57600, 'max': 99600}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg = browser.aggregate()\n",
    "agg.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da170e08",
   "metadata": {},
   "source": [
    "#### Per Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21cebb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'region': 'Brazil', 'total': 193200, 'average': 64400.0, 'min': 57600, 'max': 73200}\n",
      "{'region': 'India', 'total': 331200, 'average': 82800.0, 'min': 69600, 'max': 94800}\n",
      "{'region': 'USA', 'total': 243800, 'average': 81266.66666666667, 'min': 64800, 'max': 99600}\n"
     ]
    }
   ],
   "source": [
    "region = browser.aggregate(drilldown=[\"region\"])\n",
    "for record in region:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ef8e98",
   "metadata": {},
   "source": [
    "#### Online Shopper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de92e271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'online_shop': 'No', 'total': 386400, 'average': 77280.0, 'min': 62400, 'max': 99600}\n",
      "{'online_shop': 'Yes', 'total': 381800, 'average': 76360.0, 'min': 57600, 'max': 94800}\n"
     ]
    }
   ],
   "source": [
    "online = browser.aggregate(drilldown=[\"online_shop\"])\n",
    "for record in online:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8b3029",
   "metadata": {},
   "source": [
    "#### Aged 40-50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c57d0c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'total': 451400, 'average': 75233.33333333333, 'min': 62400, 'max': 86400}\n"
     ]
    }
   ],
   "source": [
    "import cubes as cubes\n",
    "\n",
    "cuts = [cubes.RangeCut(\"age\", [40], [50])]\n",
    "cell = cubes.Cell(cube, cuts)\n",
    "result = browser.aggregate(cell, drilldown=[\"age\"])\n",
    "print(result.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c66c195",
   "metadata": {},
   "source": [
    "# Part 2 of 2\n",
    "# Questions\n",
    "1. Consider a dataset \n",
    " that contains only two observations \n",
    " and \n",
    ". Suppose that the class of the first observation is \n",
    " and that the class of the second observation is \n",
    ". How would a 1-nearest neighbour classifier based on the Euclidean distance classify the observation \n",
    "? What are the distances between this new observation and each observation in the dataset?\n",
    "1. Consider a dataset \n",
    " that only contains observations of two different classes. Explain why a \n",
    "-nearest neighbour classifier does not need a tie-breaking policy when \n",
    " is odd.\n",
    "1. Explain why a classifier that obtains an accuracy of \n",
    " can be terrible for some datasets.\n",
    "1. Consider a classifier tasked with predicting whether an observation belongs to class \n",
    " (positive class). Suppose that this classifier has precision \n",
    " and recall \n",
    " on a test dataset. If this classifier predicts that an observation does not belong to class \n",
    ", should it be trusted? Should it be trusted if it predicts that the observation belongs to class \n",
    "?\n",
    "1. Based on the confusion matrix shown in this lab notebook, what is the pair of classes that is most confusing for the \n",
    "-nearest neighbour classifier trained in the previous sections?\n",
    "1. Train a support vector machine classifier using the same (subsampled) training dataset used in the previous sections and compute its accuracy on the corresponding test dataset. You can use the default hyperparameters for the class SVC from sklearn.svm. Show the code in the report.\n",
    "1. Using the same (subsampled) training dataset used in the previous sections, employ GridSearchCV to find the best hyperparameter settings based on 5-fold cross-validation for a RandomForestClassifier. Consider n_estimators \n",
    " and max_features \n",
    ". Use the default values for the remaining hyperparameters. Compute the accuracy of the best model on the corresponding test dataset. Show the code in the report.\n",
    "\n",
    "\n",
    "## Question 1\n",
    "$\\mathbf{x} = (-2, 3)$ will be classified as class 1, because it is closer to (-1,1) than it is (1, -1)\n",
    "\n",
    "For (-1, 1) (Class 1): $\\sqrt{(-2 - -1)^2 + (3 - 1)^2} = \\sqrt{5} â‰ˆ 2.2$\n",
    "\n",
    "For (1, -1) (Class 0): $\\sqrt{(-2 - 1)^2 + (3 - -1)^2} = \\sqrt{25} = 5$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7dd8d30",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "The hyper parameter $k$ means that the algorithm looks at k-number of nearest neighbours. A new point is assigned to the class of the majority of the nearest neighbours. When there are only two classes, if $k$ is three, five or any odd number, there will never be a tie break because there will never be an equal amount of each class. For example, 3/2 = 1.5; there is only ever an integer amount in each class. However, if k was 4, then there could be a tie break because you may have two neighbours of each class. Thus, tie breaks will not happen if $k$ is not a multiple of the number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96df16bc",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Every attribute is given an equal weight, therefore the classifier of 99.9% may be vulnerable to noise. In a terrible dataset where there is an imbalance of classes, like 99.9% of one class and 0.1% of the other, then the accuracy will always be 99.9% because of this imbalance. Although the accuracy is high, it is pointless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f645e64",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "A precision of 1.0 shows that there are no false positives, and so all positives are truly positive. This means you can fully trust in the classifier if it predicts a belonging to class y.\n",
    "\n",
    "However, a recall of 0.1 suggests that only 10% of the truly positive observations are classified as positive. So although the precision suggests everything it detects as positive is positive, from the recall value it is missing out 90% of all the positives, so you should not trust it to tell you that something *is not* positive."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb45cce5",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "Class 9 has the second lowest precision and first lowest recall, and from the confusion matrix, the classifier is classifying 4 true class 9 observations as class 4. Similarly, 3 true class 4 observations are being classified as class 9. Therefore, class 4 and 9 are the most confusing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af880ae6",
   "metadata": {},
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8fb1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "X, y = pickle.load(f, encoding='latin1')[0]\n",
    "f.close()\n",
    "\n",
    "sample_size = 2000\n",
    "X, y = X[:sample_size], y[:sample_size]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be54e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset accuracy (Support Vector Machines): 0.979375.\n",
      "Test dataset accuracy (Support Vector Machines): 0.9275.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "print('Train dataset accuracy (Support Vector Machines): {0}.'.format(clf.score(X_train, y_train)))\n",
    "print('Test dataset accuracy (Support Vector Machines): {0}.'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3078e7e0",
   "metadata": {},
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b5787d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter setting: RandomForestClassifier(max_features=0.1, n_estimators=200).\n",
      "Average accuracy across folds of best hyperparameter setting: 0.911875.\n",
      "Test dataset accuracy of best hyperparameter setting: 0.91.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_features': [0.1, 0.25]}\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_gs = GridSearchCV(rfc, parameters, cv=5)\n",
    "rfc_gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best hyperparameter setting: {0}.'.format(rfc_gs.best_estimator_))\n",
    "print('Average accuracy across folds of best hyperparameter setting: {0}.'.format(rfc_gs.best_score_))\n",
    "print('Test dataset accuracy of best hyperparameter setting: {0}.'.format(rfc_gs.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
